import tensorflow as tf
import cv2
import os
import matplotlib.pyplot as plt
import numpy as np

img = cv2.imread("c:\ML\photo_3.jpg")

plt.imshow(img)

plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))      ##converting BGR color to RGB color of the variable img.

img.shape

Datadirectory = "C:\ML\datasets"           ##dataset location
Classes = ["with_mask","without_mask"]     ##Classes of datasets
for category in Classes:
    path = os.path.join(Datadirectory, category)          ##
    for img in os.listdir(path):
        img = cv2.imread(os.path.join(path, img))
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.show()
        break
    break

plt.imshow(img)

plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))

img_size = 224               ##imagenet - imagesize must be 224 x 224

new = cv2.resize (img, (img_size, img_size))
plt.imshow(cv2.cvtColor(new, cv2.COLOR_BGR2RGB))
plt.show()

## Will now read the image and converting them into a array

## Here we will need data and then we will need label 

training_data = []

def create_training_data():
    for category in Classes:
        path = os.path.join(Datadirectory, category)
        class_num = Classes.index(category)
        for img in os.listdir(path):
            try:
                img = cv2.imread(os.path.join(path, img))
                new = cv2.resize(img, (img_size, img_size))
                training_data.append([new, class_num])
            except Exception as e:
                pass

create_training_data()

print(len(training_data))

import random

random.shuffle(training_data)

x = []
y = []

for features, label in training_data:
    x.append(features)
    y.append(label)
    
    
x = np.array(x).reshape(-1, img_size, img_size, 3)

##Normalizing the data
x = x/255.0;       ##Here 255.0 is the pixels size of the img

x.shape

Y = np.array(y)

import pickle

pickle_out = open("x.pickle","wb")
pickle.dump(x, pickle_out)
pickle_out.close()

pickle_out = open("y.pickle","wb")
pickle.dump(y, pickle_out)
pickle_out.close()

pickle_in = open("x.pickle", "rb")
x = pickle.load(pickle_in)

pickle_in = open("y.pickle", "rb")
y = pickle.load(pickle_in)

import tensorflow as tf
from tensorflow import keras         ##Using Keras API
from tensorflow.keras import layers

model = tf.keras.applications.mobilenet.MobileNet()         ##pre-trained model

base_input = model.layers[0].input

base_output = model.layers[-4].output

Flat_layer = layers.Flatten()(base_output)
final_output = layers.Dense(1)(Flat_layer)    ##Taking 0 and 1
final_output = layers.Activation('sigmoid')(final_output)

new_model = keras.Model(inputs = base_input, outputs = final_output)

import tensorflow as tf
import numpy as np

new_model.compile(loss = "binary_crossentropy", optimizer = "adam", metrics = ["accuracy"])

new_model.fit(x,Y, epochs = 1, validation_split = 0.1)

new_model.save('my_model.h5')

new_model = tf.keras.models.load_model('my_model.h5')

##Checking the network for pridictions

import tensorflow as tf
import cv2
import os
import matplotlib.pyplot as plt
import numpy as np

frame = cv2.imread('c:\Ml\datasets\with_mask\pr-antiviral-face-mask-20120321.jpg')

plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

final_image = cv2.resize(frame, (224,224))
final_image = np.expand_dims(final_image, axis = 0)    ##This need a 4th dimension..
final_image = final_image/255.0

predictions = new_model.predict(final_image)

predictions

## Testing unknown images

frame = cv2.imread("c:\ML\download.jpg")

plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

frame = cv2.imread("c:\ML\datasets\without_mask\hi.jpg")

plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

frame.shape

facecascade = cv2.CascadeClassifier('c:\ML\haarcascades\haarcascade_frontalface_default.xml')

facecascade.detectMultiScale(frame)

while True:
    facecascade .detectMultiScale(frame)
    for x,y,w,h in facecascade.detectMultiScale(frame):
        cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,255), 4)
    cv2.imshow('result',frame)
    if cv2.waitKey(2) == 27: #click esc to exit the loop
        break
cv2.destroyAllWindows()

facecascade.detectMultiScale(img)

while True:
    facecascade.detectMultiScale(img)
    for x,y,w,h in facecascade.detectMultiScale(img):
        cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,255), 4)
    cv2.imshow('result',img)
    if cv2.waitKey(2) == 27: #click esc to exit the loop
        break
cv2.destroyAllWindows()

mouthcascade = cv2.CascadeClassifier('c:\ML\haarcascades\haarcascade_smile.xml')

gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

gray.shape

bw_threshold = 120

mouthcascade.detectMultiScale(img)

while True:
    mouthcascade.detectMultiScale(img)
    for x,y,w,h in mouthcascade.detectMultiScale(img):
        cv2.rectangle(img, (x,y), (x+w, y+h), (255,0,255), 4)
    cv2.imshow('result',img)
    if cv2.waitKey(2) == 27: #click esc to exit the loop
        break
cv2.destroyAllWindows()

(thresh, black_and_white) = cv2.threshold(gray, bw_threshold, 255, cv2.THRESH_BINARY)

faces = facecascade.detectMultiScale(gray,1.1,4)
faces_bw = facecascade.detectMultiScale(black_and_white, 1.1, 4)
for x,y,w,h in faces:
    roi_gray = gray[y: y+h, x: x+w]
    roi_color = frame[y: y+h, x: x+w]
    cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 2)
    faces2 = facecascade.detectMultiScale(roi_gray)
    if (len(faces2) == 0 and len(faces_bw) == 0):
        print("Face Not Detected")
        
    else: 
        for (ex,ey,ew,eh) in faces2:
            face_roi = roi_color[ey: ey+eh, ex: ex + ew]
            print("Face Detected")

mouth = mouthcascade.detectMultiScale(gray, 1.5, 5)
if(len(mouth) == 0):
    print("Face Mask Detected")
else:
    for (mx,my,mw,mh) in mouth:
        if (y<my<y+h):
            print("Face Mask Not Detected")
            break

plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

plt.imshow(cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB))

final_image = cv2.resize(face_roi, (224,224))
final_image = np.expand_dims(final_image, axis = 0)
final_image = final_image/255.0

predictions = new_model.predict(final_image)

img.shape

predictions

import cv2
import numpy as np
import tensorflow as tf
import os
import matplotlib.pyplot as plt
from deepface import DeepFace 

path = "c:\ML\haarcascades\haarcascade_frontalface_default.xml"
font_scale = 1.5
font = cv2.FONT_HERSHEY_PLAIN

rectangle_bgr = (255, 255, 255)
img = np.zeros((500,500))
text = "some text in a box!"
(text_width, text_height) = cv2.getTextSize(text, font, fontScale = font_scale, thickness = 1)[0]
text_offset_x = 10
text_offset_y = img.shape[0] - 25
box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width +2, text_offset_y - text_height -2))
cv2.rectangle(img, box_coords[0], box_coords[1], rectangle_bgr, cv2.FILLED)
cv2.putText(img, text, (text_offset_x, text_offset_y), font, fontScale = font_scale, color = (0,0,0), thickness=1)

cap = cv2.VideoCapture(0)
if not cap.isOpened():
    cap = cv2.VideoCapture(0)
if not cap.isOpened():
    raise IOError("cannot open webcam")
    
while True:
    ret, frame = cap.read()
    faceCascade = cv2.CascadeClassifier('c:\ML\haarcascades\haarcascade_frontalface_default.xml')
   ##mouthcascade = cv2.CascadeClassifier('c:\ML\haarcascades\haarcascade_smile.xml')
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = faceCascade.detectMultiScale(gray,1.1,4)
    for x,y,w,h in faces:
        roi_gray = gray[y:y+h, x:x+w]
        roi_color = frame[y:y+h, x:x+w]
        cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 2)
        facess = faceCascade.detectMultiScale(roi_gray)
        if len(facess) == 0:
            print("Face not detected")
        else:
            for(ex,ey,ew,eh) in faces:
                face_roi = roi_color[ey: ey+eh, ex:ex + ew] ##Cropping the face
      
    ##final_image = cv2.resize(face_roi, (224,224))
    ##final_image = np.expand_dims(final_image, axis = 0)
    ##final_image = final_image/255.0
    
    font = cv2.FONT_HERSHEY_SIMPLEX         ##TEXT FONT
    predictions = new_model.predict(final_image)
    
    if(predictions==0):
        status = "NO MASK Detected, please wear a mask."
        
        x1, y1, w1, h1 = 0,0,175,75
        cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0,0,0), -1)
        cv2.putText(frame, status, (x1 + int(w1/10),y1 + int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)
        
        cv2.putText(frame, status,(100, 150), font, 3, (0,0,255),2,cv2.LINE_4)
        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,0,255))
        
    else:
        status = "FACE MASK Detected, thank you for wearing one!"
        
        x1,y1,w1,h1 = 0,0,175,75
        cv2.rectangle(frame, (x1,x1), (x1+w1, y1+h1), (0,0,0), -1)
        cv2.putText(frame, status, (x1 + int(w1/10), y1 + int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)
        cv2.putText(frame, status, (100, 150), font, 3, (0, 255, 0),2,cv2.LINE_4)
        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0))
        
    
    cv2.imshow('FACE MASK DETECTION', frame)
   
    if cv2.waitKey(2) == 27 & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()